{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.ipynb_checkpoints', '0.py', '2.csv', '3.csv', '3chTest', '3chTrain', 'a.jpg', 'batches.meta', 'checkpoint', 'data', 'data_batch_1', 'data_batch_2', 'data_batch_3', 'data_batch_4', 'data_batch_5', 'imageChangeChannel.ipynb', 'readme.html', 'resize.py', 'SSGAN_VS_CNN-Copy1.ipynb', 'SSGAN_VS_CNN.ipynb', 'test', 'test.png', 'test1.png', 'test2', 'test2.png', 'test3', 'testNew', 'test_batch', 'test_cifar10', 'train', 'train2', 'train3', 'trainNew', 'train_cifar10', 'Untitled-Copy1.ipynb', 'Untitled1.ipynb']\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import slim\n",
    "CIFAR_DIR = \"../cifar-10-batches-py\"\n",
    "print(os.listdir(CIFAR_DIR))\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "def load_Traindata():\n",
    "    train = []\n",
    "    file_names = os.listdir('./3chTrain/')\n",
    "    for i in range(len(file_names)):\n",
    "        im = Image.open('./3chTrain/'+file_names[i])\n",
    "        im2 = np.array(im)\n",
    "        train.append(im2)\n",
    "    train2 = np.array(train)\n",
    "    \n",
    "    #test2 = np.array(test)\n",
    "    train_lable = np.zeros((len(train2),1),dtype='int8')\n",
    "    #test_lable = np.zeros((len(test2),1),dtype='int8')\n",
    "    for i in range(6):\n",
    "        for j in range(i*1346, (i+1)*1346):\n",
    "            train_lable[j,0] = i\n",
    "   \n",
    "    train_lable = train_lable.reshape((train_lable.shape[0],))\n",
    "    return (train2, train_lable)\n",
    "def load_Testdata():\n",
    "    test = []\n",
    "    file_names = os.listdir('./3chTest/')\n",
    "    for i in range(len(file_names)):\n",
    "        im = Image.open('./3chTest/'+file_names[i])\n",
    "        im2 = np.array(im)\n",
    "        test.append(im2)\n",
    "    test2 = np.array(test)\n",
    "    #train_lable = np.zeros((len(train2),1),dtype='int8')\n",
    "    test_lable = np.zeros((len(test2),1),dtype='int8')\n",
    "    for i in range(6):\n",
    "        for j in range(i*800, (i+1)*800):\n",
    "            test_lable[j,0] = i\n",
    "    test_lable = test_lable.reshape((test_lable.shape[0],))\n",
    "    return (test2, test_lable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load(checkpoint_dir, saver, sess):\n",
    "    import re\n",
    "    print(\" [*] Reading checkpoints...\")\n",
    "    ckpt = tf.train.get_checkpoint_state(checkpoint_dir)\n",
    "    if ckpt and ckpt.model_checkpoint_path:\n",
    "        ckpt_name = os.path.basename(ckpt.model_checkpoint_path)\n",
    "        saver.restore(sess, os.path.join(checkpoint_dir, ckpt_name))\n",
    "        counter = int(next(re.finditer(\"(\\d+)(?!.*\\d)\", ckpt_name)).group(0))\n",
    "        print(\" [*] Success to read {}\".format(ckpt_name))\n",
    "        return True, counter\n",
    "    else:\n",
    "        print(\" [*] Failed to find a checkpoint\")\n",
    "        return False, 0\n",
    "\n",
    "\n",
    "def save(checkpoint_dir, step, saver, sess):\n",
    "    model_name = \"cDCGAN.model\"\n",
    "    if not os.path.exists(checkpoint_dir):\n",
    "        os.makedirs(checkpoint_dir)\n",
    "    saver.save(sess, os.path.join(checkpoint_dir, model_name), global_step=step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8076, 64, 64, 3)\n",
      "(8076,)\n",
      "(4800, 64, 64, 3)\n",
      "(4800,)\n"
     ]
    }
   ],
   "source": [
    "class SteelData:\n",
    "    def __init__(self,  need_shuffle, isTrain):\n",
    "        all_data = []\n",
    "        all_labels = []\n",
    "        if isTrain:\n",
    "            data, labels = load_Traindata()\n",
    "        else:\n",
    "            data, labels = load_Testdata()\n",
    "        all_data.append(data)\n",
    "        all_labels.append(labels)\n",
    "        self._data = np.vstack(all_data)\n",
    "        self._data = self._data / 127.5 - 1\n",
    "        self._labels = np.hstack(all_labels)\n",
    "        print(self._data.shape)\n",
    "        print(self._labels.shape)\n",
    "        \n",
    "        self._num_examples = self._data.shape[0]\n",
    "        self._need_shuffle = need_shuffle\n",
    "        self._indicator = 0\n",
    "        if self._need_shuffle:\n",
    "            self._shuffle_data()\n",
    "            \n",
    "    def _shuffle_data(self):\n",
    "        # [0,1,2,3,4,5] -> [5,3,2,4,0,1]\n",
    "        p = np.random.permutation(self._num_examples)\n",
    "        self._data = self._data[p]\n",
    "        self._labels = self._labels[p]\n",
    "    \n",
    "    def next_batch(self, batch_size):\n",
    "        \"\"\"return batch_size examples as a batch.\"\"\"\n",
    "        end_indicator = self._indicator + batch_size\n",
    "        if end_indicator > self._num_examples:\n",
    "            if self._need_shuffle:\n",
    "                self._shuffle_data()\n",
    "                self._indicator = 0\n",
    "                end_indicator = batch_size\n",
    "            else:\n",
    "                raise Exception(\"have no more examples\")\n",
    "        if end_indicator > self._num_examples:\n",
    "            raise Exception(\"batch size is larger than all examples\")\n",
    "        batch_data = self._data[self._indicator: end_indicator]\n",
    "        batch_labels = self._labels[self._indicator: end_indicator]\n",
    "        self._indicator = end_indicator\n",
    "        return batch_data, batch_labels\n",
    "\n",
    "#train_filenames = [os.path.join(CIFAR_DIR, 'train' % i) for i in range(1, 6)]\n",
    "#test_filenames = [os.path.join(CIFAR_DIR, 'test_batch')]\n",
    "\n",
    "train_data = SteelData(True, True)\n",
    "test_data = SteelData(False,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [*] Reading checkpoints...\n",
      "INFO:tensorflow:Restoring parameters from ./checkpoint/train_cDCGAN\\cDCGAN.model-421\n",
      " [*] Success to read cDCGAN.model-421\n",
      " [*] Load SUCCESS\n",
      "[Train] Step: 500, loss: 0.00000, acc: 1.00000\n",
      "(4800, 64, 64, 3)\n",
      "(4800,)\n",
      "[Test ] Step: 500, acc: 0.53125\n",
      "[Train] Step: 1000, loss: 0.00000, acc: 1.00000\n",
      "(4800, 64, 64, 3)\n",
      "(4800,)\n",
      "[Test ] Step: 1000, acc: 0.53125\n",
      "[Train] Step: 1500, loss: 0.00000, acc: 1.00000\n",
      "(4800, 64, 64, 3)\n",
      "(4800,)\n",
      "[Test ] Step: 1500, acc: 0.53125\n",
      "[Train] Step: 2000, loss: 0.00000, acc: 1.00000\n",
      "(4800, 64, 64, 3)\n",
      "(4800,)\n",
      "[Test ] Step: 2000, acc: 0.53125\n",
      "[Train] Step: 2500, loss: 0.00000, acc: 1.00000\n",
      "(4800, 64, 64, 3)\n",
      "(4800,)\n",
      "[Test ] Step: 2500, acc: 0.54688\n",
      "[Train] Step: 3000, loss: 0.00000, acc: 1.00000\n",
      "(4800, 64, 64, 3)\n",
      "(4800,)\n",
      "[Test ] Step: 3000, acc: 0.54688\n",
      "[Train] Step: 3500, loss: 0.00000, acc: 1.00000\n",
      "(4800, 64, 64, 3)\n",
      "(4800,)\n",
      "[Test ] Step: 3500, acc: 0.54688\n",
      "[Train] Step: 4000, loss: 0.00000, acc: 1.00000\n",
      "(4800, 64, 64, 3)\n",
      "(4800,)\n",
      "[Test ] Step: 4000, acc: 0.53125\n",
      "[Train] Step: 4500, loss: 0.00000, acc: 1.00000\n",
      "(4800, 64, 64, 3)\n",
      "(4800,)\n",
      "[Test ] Step: 4500, acc: 0.53125\n",
      "[Train] Step: 5000, loss: 0.00000, acc: 1.00000\n",
      "(4800, 64, 64, 3)\n",
      "(4800,)\n",
      "[Test ] Step: 5000, acc: 0.53125\n",
      "[Train] Step: 5500, loss: 0.00000, acc: 1.00000\n",
      "(4800, 64, 64, 3)\n",
      "(4800,)\n",
      "[Test ] Step: 5500, acc: 0.57812\n",
      "[Train] Step: 6000, loss: 0.00000, acc: 1.00000\n",
      "(4800, 64, 64, 3)\n",
      "(4800,)\n",
      "[Test ] Step: 6000, acc: 0.56250\n",
      "[Train] Step: 6500, loss: 0.00000, acc: 1.00000\n",
      "(4800, 64, 64, 3)\n",
      "(4800,)\n",
      "[Test ] Step: 6500, acc: 0.59375\n",
      "[Train] Step: 7000, loss: 0.00000, acc: 1.00000\n",
      "(4800, 64, 64, 3)\n",
      "(4800,)\n",
      "[Test ] Step: 7000, acc: 0.56250\n",
      "[Train] Step: 7500, loss: 0.00000, acc: 1.00000\n",
      "(4800, 64, 64, 3)\n",
      "(4800,)\n",
      "[Test ] Step: 7500, acc: 0.50000\n",
      "[Train] Step: 8000, loss: 0.00000, acc: 1.00000\n",
      "(4800, 64, 64, 3)\n",
      "(4800,)\n",
      "[Test ] Step: 8000, acc: 0.53125\n",
      "[Train] Step: 8500, loss: 0.00000, acc: 1.00000\n",
      "(4800, 64, 64, 3)\n",
      "(4800,)\n",
      "[Test ] Step: 8500, acc: 0.53125\n",
      "[Train] Step: 9000, loss: 0.00000, acc: 1.00000\n",
      "(4800, 64, 64, 3)\n",
      "(4800,)\n",
      "[Test ] Step: 9000, acc: 0.53125\n",
      "[Train] Step: 9500, loss: 0.00000, acc: 1.00000\n",
      "(4800, 64, 64, 3)\n",
      "(4800,)\n",
      "[Test ] Step: 9500, acc: 0.42188\n",
      "[Train] Step: 10000, loss: 0.00000, acc: 1.00000\n",
      "(4800, 64, 64, 3)\n",
      "(4800,)\n",
      "[Test ] Step: 10000, acc: 0.62500\n",
      "[Train] Step: 10500, loss: 0.00000, acc: 1.00000\n",
      "(4800, 64, 64, 3)\n",
      "(4800,)\n",
      "[Test ] Step: 10500, acc: 0.56250\n",
      "[Train] Step: 11000, loss: 0.00000, acc: 1.00000\n",
      "(4800, 64, 64, 3)\n",
      "(4800,)\n",
      "[Test ] Step: 11000, acc: 0.56250\n",
      "[Train] Step: 11500, loss: 0.00000, acc: 1.00000\n",
      "(4800, 64, 64, 3)\n",
      "(4800,)\n",
      "[Test ] Step: 11500, acc: 0.62500\n",
      "[Train] Step: 12000, loss: 0.00000, acc: 1.00000\n",
      "(4800, 64, 64, 3)\n",
      "(4800,)\n",
      "[Test ] Step: 12000, acc: 0.68750\n",
      "[Train] Step: 12500, loss: 0.00000, acc: 1.00000\n",
      "(4800, 64, 64, 3)\n",
      "(4800,)\n",
      "[Test ] Step: 12500, acc: 0.57812\n",
      "[Train] Step: 13000, loss: 0.00000, acc: 1.00000\n",
      "(4800, 64, 64, 3)\n",
      "(4800,)\n",
      "[Test ] Step: 13000, acc: 0.57812\n",
      "[Train] Step: 13500, loss: 0.00000, acc: 1.00000\n",
      "(4800, 64, 64, 3)\n",
      "(4800,)\n",
      "[Test ] Step: 13500, acc: 0.60938\n",
      "[Train] Step: 14000, loss: 0.00000, acc: 1.00000\n",
      "(4800, 64, 64, 3)\n",
      "(4800,)\n",
      "[Test ] Step: 14000, acc: 0.60938\n",
      "[Train] Step: 14500, loss: 0.00000, acc: 1.00000\n",
      "(4800, 64, 64, 3)\n",
      "(4800,)\n",
      "[Test ] Step: 14500, acc: 0.65625\n",
      "[Train] Step: 15000, loss: 0.00000, acc: 1.00000\n",
      "(4800, 64, 64, 3)\n",
      "(4800,)\n",
      "[Test ] Step: 15000, acc: 0.60938\n",
      "[Train] Step: 15500, loss: 0.00021, acc: 1.00000\n",
      "(4800, 64, 64, 3)\n",
      "(4800,)\n",
      "[Test ] Step: 15500, acc: 0.59375\n",
      "[Train] Step: 16000, loss: 0.00000, acc: 1.00000\n",
      "(4800, 64, 64, 3)\n",
      "(4800,)\n",
      "[Test ] Step: 16000, acc: 0.51562\n",
      "[Train] Step: 16500, loss: 0.00000, acc: 1.00000\n",
      "(4800, 64, 64, 3)\n",
      "(4800,)\n",
      "[Test ] Step: 16500, acc: 0.62500\n",
      "[Train] Step: 17000, loss: 0.00000, acc: 1.00000\n",
      "(4800, 64, 64, 3)\n",
      "(4800,)\n",
      "[Test ] Step: 17000, acc: 0.54688\n",
      "[Train] Step: 17500, loss: 0.00000, acc: 1.00000\n",
      "(4800, 64, 64, 3)\n",
      "(4800,)\n",
      "[Test ] Step: 17500, acc: 0.60938\n",
      "[Train] Step: 18000, loss: 0.00000, acc: 1.00000\n",
      "(4800, 64, 64, 3)\n",
      "(4800,)\n",
      "[Test ] Step: 18000, acc: 0.67188\n",
      "[Train] Step: 18500, loss: 0.00000, acc: 1.00000\n",
      "(4800, 64, 64, 3)\n",
      "(4800,)\n",
      "[Test ] Step: 18500, acc: 0.67188\n",
      "[Train] Step: 19000, loss: 0.00000, acc: 1.00000\n",
      "(4800, 64, 64, 3)\n",
      "(4800,)\n",
      "[Test ] Step: 19000, acc: 0.62500\n",
      "[Train] Step: 19500, loss: 0.00000, acc: 1.00000\n",
      "(4800, 64, 64, 3)\n",
      "(4800,)\n",
      "[Test ] Step: 19500, acc: 0.64062\n",
      "[Train] Step: 20000, loss: 0.00000, acc: 1.00000\n",
      "(4800, 64, 64, 3)\n",
      "(4800,)\n",
      "[Test ] Step: 20000, acc: 0.57812\n",
      "[Train] Step: 20500, loss: 0.00000, acc: 1.00000\n",
      "(4800, 64, 64, 3)\n",
      "(4800,)\n",
      "[Test ] Step: 20500, acc: 0.62500\n",
      "[Train] Step: 21000, loss: 0.00000, acc: 1.00000\n",
      "(4800, 64, 64, 3)\n",
      "(4800,)\n",
      "[Test ] Step: 21000, acc: 0.64062\n",
      "[Train] Step: 21500, loss: 0.00000, acc: 1.00000\n",
      "(4800, 64, 64, 3)\n",
      "(4800,)\n",
      "[Test ] Step: 21500, acc: 0.62500\n",
      "[Train] Step: 22000, loss: 0.00000, acc: 1.00000\n",
      "(4800, 64, 64, 3)\n",
      "(4800,)\n",
      "[Test ] Step: 22000, acc: 0.67188\n",
      "[Train] Step: 22500, loss: 0.00000, acc: 1.00000\n",
      "(4800, 64, 64, 3)\n",
      "(4800,)\n",
      "[Test ] Step: 22500, acc: 0.68750\n",
      "[Train] Step: 23000, loss: 0.00000, acc: 1.00000\n",
      "(4800, 64, 64, 3)\n",
      "(4800,)\n",
      "[Test ] Step: 23000, acc: 0.73438\n",
      "[Train] Step: 23500, loss: 0.00000, acc: 1.00000\n",
      "(4800, 64, 64, 3)\n",
      "(4800,)\n",
      "[Test ] Step: 23500, acc: 0.67188\n",
      "[Train] Step: 24000, loss: 0.00000, acc: 1.00000\n",
      "(4800, 64, 64, 3)\n",
      "(4800,)\n",
      "[Test ] Step: 24000, acc: 0.62500\n",
      "[Train] Step: 24500, loss: 0.00000, acc: 1.00000\n",
      "(4800, 64, 64, 3)\n",
      "(4800,)\n",
      "[Test ] Step: 24500, acc: 0.59375\n",
      "[Train] Step: 25000, loss: 0.03648, acc: 0.98438\n",
      "(4800, 64, 64, 3)\n",
      "(4800,)\n",
      "[Test ] Step: 25000, acc: 0.60938\n",
      "[Train] Step: 25500, loss: 0.00000, acc: 1.00000\n",
      "(4800, 64, 64, 3)\n",
      "(4800,)\n",
      "[Test ] Step: 25500, acc: 0.57812\n",
      "[Train] Step: 26000, loss: 0.00000, acc: 1.00000\n",
      "(4800, 64, 64, 3)\n",
      "(4800,)\n",
      "[Test ] Step: 26000, acc: 0.56250\n",
      "[Train] Step: 26500, loss: 0.00000, acc: 1.00000\n",
      "(4800, 64, 64, 3)\n",
      "(4800,)\n",
      "[Test ] Step: 26500, acc: 0.62500\n",
      "[Train] Step: 27000, loss: 0.00000, acc: 1.00000\n",
      "(4800, 64, 64, 3)\n",
      "(4800,)\n",
      "[Test ] Step: 27000, acc: 0.62500\n",
      "[Train] Step: 27500, loss: 0.00000, acc: 1.00000\n",
      "(4800, 64, 64, 3)\n",
      "(4800,)\n",
      "[Test ] Step: 27500, acc: 0.57812\n",
      "[Train] Step: 28000, loss: 0.00000, acc: 1.00000\n",
      "(4800, 64, 64, 3)\n",
      "(4800,)\n",
      "[Test ] Step: 28000, acc: 0.53125\n",
      "[Train] Step: 28500, loss: 0.00000, acc: 1.00000\n",
      "(4800, 64, 64, 3)\n",
      "(4800,)\n",
      "[Test ] Step: 28500, acc: 0.53125\n",
      "[Train] Step: 29000, loss: 0.00000, acc: 1.00000\n",
      "(4800, 64, 64, 3)\n",
      "(4800,)\n",
      "[Test ] Step: 29000, acc: 0.60938\n",
      "[Train] Step: 29500, loss: 0.00000, acc: 1.00000\n",
      "(4800, 64, 64, 3)\n",
      "(4800,)\n",
      "[Test ] Step: 29500, acc: 0.57812\n",
      "[Train] Step: 30000, loss: 0.00000, acc: 1.00000\n",
      "(4800, 64, 64, 3)\n",
      "(4800,)\n",
      "[Test ] Step: 30000, acc: 0.57812\n",
      "[Train] Step: 30500, loss: 0.00000, acc: 1.00000\n",
      "(4800, 64, 64, 3)\n",
      "(4800,)\n",
      "[Test ] Step: 30500, acc: 0.59375\n",
      "[Train] Step: 31000, loss: 0.00000, acc: 1.00000\n",
      "(4800, 64, 64, 3)\n",
      "(4800,)\n",
      "[Test ] Step: 31000, acc: 0.59375\n",
      "[Train] Step: 31500, loss: 0.00000, acc: 1.00000\n",
      "(4800, 64, 64, 3)\n",
      "(4800,)\n",
      "[Test ] Step: 31500, acc: 0.59375\n",
      "[Train] Step: 32000, loss: 0.00000, acc: 1.00000\n",
      "(4800, 64, 64, 3)\n",
      "(4800,)\n",
      "[Test ] Step: 32000, acc: 0.56250\n",
      "[Train] Step: 32500, loss: 0.00001, acc: 1.00000\n",
      "(4800, 64, 64, 3)\n",
      "(4800,)\n",
      "[Test ] Step: 32500, acc: 0.56250\n",
      "[Train] Step: 33000, loss: 0.00000, acc: 1.00000\n",
      "(4800, 64, 64, 3)\n",
      "(4800,)\n",
      "[Test ] Step: 33000, acc: 0.64062\n",
      "[Train] Step: 33500, loss: 0.00000, acc: 1.00000\n",
      "(4800, 64, 64, 3)\n",
      "(4800,)\n",
      "[Test ] Step: 33500, acc: 0.62500\n",
      "[Train] Step: 34000, loss: 0.00000, acc: 1.00000\n",
      "(4800, 64, 64, 3)\n",
      "(4800,)\n",
      "[Test ] Step: 34000, acc: 0.60938\n",
      "[Train] Step: 34500, loss: 0.00000, acc: 1.00000\n",
      "(4800, 64, 64, 3)\n",
      "(4800,)\n",
      "[Test ] Step: 34500, acc: 0.59375\n",
      "[Train] Step: 35000, loss: 0.00000, acc: 1.00000\n",
      "(4800, 64, 64, 3)\n",
      "(4800,)\n",
      "[Test ] Step: 35000, acc: 0.62500\n",
      "[Train] Step: 35500, loss: 0.00000, acc: 1.00000\n",
      "(4800, 64, 64, 3)\n",
      "(4800,)\n",
      "[Test ] Step: 35500, acc: 0.62500\n",
      "[Train] Step: 36000, loss: 0.00000, acc: 1.00000\n",
      "(4800, 64, 64, 3)\n",
      "(4800,)\n",
      "[Test ] Step: 36000, acc: 0.62500\n",
      "[Train] Step: 36500, loss: 0.00000, acc: 1.00000\n",
      "(4800, 64, 64, 3)\n",
      "(4800,)\n",
      "[Test ] Step: 36500, acc: 0.62500\n",
      "[Train] Step: 37000, loss: 0.00000, acc: 1.00000\n",
      "(4800, 64, 64, 3)\n",
      "(4800,)\n",
      "[Test ] Step: 37000, acc: 0.62500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] Step: 37500, loss: 0.00000, acc: 1.00000\n",
      "(4800, 64, 64, 3)\n",
      "(4800,)\n",
      "[Test ] Step: 37500, acc: 0.62500\n",
      "[Train] Step: 38000, loss: 0.00000, acc: 1.00000\n",
      "(4800, 64, 64, 3)\n",
      "(4800,)\n",
      "[Test ] Step: 38000, acc: 0.62500\n",
      "[Train] Step: 38500, loss: 0.00000, acc: 1.00000\n",
      "(4800, 64, 64, 3)\n",
      "(4800,)\n",
      "[Test ] Step: 38500, acc: 0.68750\n",
      "[Train] Step: 39000, loss: 0.00000, acc: 1.00000\n",
      "(4800, 64, 64, 3)\n",
      "(4800,)\n",
      "[Test ] Step: 39000, acc: 0.67188\n",
      "[Train] Step: 39500, loss: 0.00000, acc: 1.00000\n",
      "(4800, 64, 64, 3)\n",
      "(4800,)\n",
      "[Test ] Step: 39500, acc: 0.59375\n",
      "[Train] Step: 40000, loss: 0.00000, acc: 1.00000\n",
      "(4800, 64, 64, 3)\n",
      "(4800,)\n",
      "[Test ] Step: 40000, acc: 0.56250\n",
      "[Train] Step: 40500, loss: 0.00000, acc: 1.00000\n",
      "(4800, 64, 64, 3)\n",
      "(4800,)\n",
      "[Test ] Step: 40500, acc: 0.75000\n",
      "[Train] Step: 41000, loss: 0.00000, acc: 1.00000\n",
      "(4800, 64, 64, 3)\n",
      "(4800,)\n",
      "[Test ] Step: 41000, acc: 0.70312\n",
      "[Train] Step: 41500, loss: 0.00000, acc: 1.00000\n",
      "(4800, 64, 64, 3)\n",
      "(4800,)\n",
      "[Test ] Step: 41500, acc: 0.60938\n",
      "[Train] Step: 42000, loss: 0.00000, acc: 1.00000\n",
      "(4800, 64, 64, 3)\n",
      "(4800,)\n",
      "[Test ] Step: 42000, acc: 0.62500\n",
      "[Train] Step: 42500, loss: 0.00000, acc: 1.00000\n",
      "(4800, 64, 64, 3)\n",
      "(4800,)\n",
      "[Test ] Step: 42500, acc: 0.65625\n",
      "[Train] Step: 43000, loss: 0.00000, acc: 1.00000\n",
      "(4800, 64, 64, 3)\n",
      "(4800,)\n",
      "[Test ] Step: 43000, acc: 0.64062\n",
      "[Train] Step: 43500, loss: 0.00000, acc: 1.00000\n",
      "(4800, 64, 64, 3)\n",
      "(4800,)\n",
      "[Test ] Step: 43500, acc: 0.64062\n",
      "[Train] Step: 44000, loss: 0.00000, acc: 1.00000\n",
      "(4800, 64, 64, 3)\n",
      "(4800,)\n",
      "[Test ] Step: 44000, acc: 0.59375\n",
      "[Train] Step: 44500, loss: 0.00000, acc: 1.00000\n",
      "(4800, 64, 64, 3)\n",
      "(4800,)\n",
      "[Test ] Step: 44500, acc: 0.64062\n",
      "[Train] Step: 45000, loss: 0.00000, acc: 1.00000\n",
      "(4800, 64, 64, 3)\n",
      "(4800,)\n",
      "[Test ] Step: 45000, acc: 0.57812\n",
      "[Train] Step: 45500, loss: 0.00000, acc: 1.00000\n",
      "(4800, 64, 64, 3)\n",
      "(4800,)\n",
      "[Test ] Step: 45500, acc: 0.57812\n",
      "[Train] Step: 46000, loss: 0.00000, acc: 1.00000\n",
      "(4800, 64, 64, 3)\n",
      "(4800,)\n",
      "[Test ] Step: 46000, acc: 0.53125\n",
      "[Train] Step: 46500, loss: 0.00000, acc: 1.00000\n",
      "(4800, 64, 64, 3)\n",
      "(4800,)\n",
      "[Test ] Step: 46500, acc: 0.56250\n",
      "[Train] Step: 47000, loss: 0.00000, acc: 1.00000\n",
      "(4800, 64, 64, 3)\n",
      "(4800,)\n",
      "[Test ] Step: 47000, acc: 0.56250\n",
      "[Train] Step: 47500, loss: 0.00000, acc: 1.00000\n",
      "(4800, 64, 64, 3)\n",
      "(4800,)\n",
      "[Test ] Step: 47500, acc: 0.54688\n",
      "[Train] Step: 48000, loss: 0.00000, acc: 1.00000\n",
      "(4800, 64, 64, 3)\n",
      "(4800,)\n",
      "[Test ] Step: 48000, acc: 0.60938\n",
      "[Train] Step: 48500, loss: 0.00000, acc: 1.00000\n",
      "(4800, 64, 64, 3)\n",
      "(4800,)\n",
      "[Test ] Step: 48500, acc: 0.50000\n",
      "[Train] Step: 49000, loss: 0.00000, acc: 1.00000\n",
      "(4800, 64, 64, 3)\n",
      "(4800,)\n",
      "[Test ] Step: 49000, acc: 0.57812\n",
      "[Train] Step: 49500, loss: 0.00000, acc: 1.00000\n",
      "(4800, 64, 64, 3)\n",
      "(4800,)\n",
      "[Test ] Step: 49500, acc: 0.56250\n",
      "[Train] Step: 50000, loss: 0.00000, acc: 1.00000\n",
      "(4800, 64, 64, 3)\n",
      "(4800,)\n",
      "[Test ] Step: 50000, acc: 0.59375\n",
      "[Train] Step: 50500, loss: 0.00000, acc: 1.00000\n",
      "(4800, 64, 64, 3)\n",
      "(4800,)\n",
      "[Test ] Step: 50500, acc: 0.59375\n",
      "[Train] Step: 51000, loss: 0.00000, acc: 1.00000\n",
      "(4800, 64, 64, 3)\n",
      "(4800,)\n",
      "[Test ] Step: 51000, acc: 0.67188\n",
      "[Train] Step: 51500, loss: 0.00000, acc: 1.00000\n",
      "(4800, 64, 64, 3)\n",
      "(4800,)\n",
      "[Test ] Step: 51500, acc: 0.59375\n",
      "[Train] Step: 52000, loss: 0.00000, acc: 1.00000\n",
      "(4800, 64, 64, 3)\n",
      "(4800,)\n",
      "[Test ] Step: 52000, acc: 0.59375\n",
      "[Train] Step: 52500, loss: 0.00000, acc: 1.00000\n",
      "(4800, 64, 64, 3)\n",
      "(4800,)\n",
      "[Test ] Step: 52500, acc: 0.75000\n",
      "[Train] Step: 53000, loss: 0.00000, acc: 1.00000\n",
      "(4800, 64, 64, 3)\n",
      "(4800,)\n",
      "[Test ] Step: 53000, acc: 0.57812\n",
      "[Train] Step: 53500, loss: 0.00000, acc: 1.00000\n",
      "(4800, 64, 64, 3)\n",
      "(4800,)\n",
      "[Test ] Step: 53500, acc: 0.62500\n",
      "[Train] Step: 54000, loss: 0.00000, acc: 1.00000\n",
      "(4800, 64, 64, 3)\n",
      "(4800,)\n",
      "[Test ] Step: 54000, acc: 0.62500\n",
      "[Train] Step: 54500, loss: 0.00000, acc: 1.00000\n",
      "(4800, 64, 64, 3)\n",
      "(4800,)\n",
      "[Test ] Step: 54500, acc: 0.57812\n",
      "[Train] Step: 55000, loss: 0.00000, acc: 1.00000\n",
      "(4800, 64, 64, 3)\n",
      "(4800,)\n",
      "[Test ] Step: 55000, acc: 0.57812\n",
      "[Train] Step: 55500, loss: 0.00000, acc: 1.00000\n",
      "(4800, 64, 64, 3)\n",
      "(4800,)\n",
      "[Test ] Step: 55500, acc: 0.65625\n",
      "[Train] Step: 56000, loss: 0.00000, acc: 1.00000\n",
      "(4800, 64, 64, 3)\n",
      "(4800,)\n",
      "[Test ] Step: 56000, acc: 0.54688\n",
      "[Train] Step: 56500, loss: 0.00000, acc: 1.00000\n",
      "(4800, 64, 64, 3)\n",
      "(4800,)\n",
      "[Test ] Step: 56500, acc: 0.64062\n",
      "[Train] Step: 57000, loss: 0.00000, acc: 1.00000\n",
      "(4800, 64, 64, 3)\n",
      "(4800,)\n",
      "[Test ] Step: 57000, acc: 0.71875\n",
      "[Train] Step: 57500, loss: 0.00000, acc: 1.00000\n",
      "(4800, 64, 64, 3)\n",
      "(4800,)\n",
      "[Test ] Step: 57500, acc: 0.68750\n",
      "[Train] Step: 58000, loss: 0.00000, acc: 1.00000\n",
      "(4800, 64, 64, 3)\n",
      "(4800,)\n",
      "[Test ] Step: 58000, acc: 0.71875\n",
      "[Train] Step: 58500, loss: 0.00000, acc: 1.00000\n",
      "(4800, 64, 64, 3)\n",
      "(4800,)\n",
      "[Test ] Step: 58500, acc: 0.65625\n",
      "[Train] Step: 59000, loss: 0.00007, acc: 1.00000\n",
      "(4800, 64, 64, 3)\n",
      "(4800,)\n",
      "[Test ] Step: 59000, acc: 0.64062\n",
      "[Train] Step: 59500, loss: 0.00000, acc: 1.00000\n",
      "(4800, 64, 64, 3)\n",
      "(4800,)\n",
      "[Test ] Step: 59500, acc: 0.64062\n",
      "[Train] Step: 60000, loss: 0.00000, acc: 1.00000\n",
      "(4800, 64, 64, 3)\n",
      "(4800,)\n",
      "[Test ] Step: 60000, acc: 0.68750\n",
      "[Train] Step: 60500, loss: 0.00000, acc: 1.00000\n",
      "(4800, 64, 64, 3)\n",
      "(4800,)\n",
      "[Test ] Step: 60500, acc: 0.62500\n",
      "[Train] Step: 61000, loss: 0.00000, acc: 1.00000\n",
      "(4800, 64, 64, 3)\n",
      "(4800,)\n",
      "[Test ] Step: 61000, acc: 0.68750\n",
      "[Train] Step: 61500, loss: 0.00000, acc: 1.00000\n",
      "(4800, 64, 64, 3)\n",
      "(4800,)\n",
      "[Test ] Step: 61500, acc: 0.37500\n",
      "[Train] Step: 62000, loss: 0.00000, acc: 1.00000\n",
      "(4800, 64, 64, 3)\n",
      "(4800,)\n",
      "[Test ] Step: 62000, acc: 0.54688\n",
      "[Train] Step: 62500, loss: 0.00000, acc: 1.00000\n",
      "(4800, 64, 64, 3)\n",
      "(4800,)\n",
      "[Test ] Step: 62500, acc: 0.53125\n",
      "[Train] Step: 63000, loss: 0.00000, acc: 1.00000\n",
      "(4800, 64, 64, 3)\n",
      "(4800,)\n",
      "[Test ] Step: 63000, acc: 0.59375\n",
      "[Train] Step: 63500, loss: 0.00000, acc: 1.00000\n",
      "(4800, 64, 64, 3)\n",
      "(4800,)\n",
      "[Test ] Step: 63500, acc: 0.62500\n",
      "[Train] Step: 64000, loss: 0.00000, acc: 1.00000\n",
      "(4800, 64, 64, 3)\n",
      "(4800,)\n",
      "[Test ] Step: 64000, acc: 0.67188\n",
      "[Train] Step: 64500, loss: 0.00000, acc: 1.00000\n",
      "(4800, 64, 64, 3)\n",
      "(4800,)\n",
      "[Test ] Step: 64500, acc: 0.65625\n",
      "[Train] Step: 65000, loss: 0.00000, acc: 1.00000\n",
      "(4800, 64, 64, 3)\n",
      "(4800,)\n",
      "[Test ] Step: 65000, acc: 0.65625\n",
      "[Train] Step: 65500, loss: 0.00000, acc: 1.00000\n",
      "(4800, 64, 64, 3)\n",
      "(4800,)\n",
      "[Test ] Step: 65500, acc: 0.65625\n",
      "[Train] Step: 66000, loss: 0.00000, acc: 1.00000\n",
      "(4800, 64, 64, 3)\n",
      "(4800,)\n",
      "[Test ] Step: 66000, acc: 0.75000\n",
      "[Train] Step: 66500, loss: 0.00000, acc: 1.00000\n",
      "(4800, 64, 64, 3)\n",
      "(4800,)\n",
      "[Test ] Step: 66500, acc: 0.73438\n",
      "[Train] Step: 67000, loss: 0.00002, acc: 1.00000\n",
      "(4800, 64, 64, 3)\n",
      "(4800,)\n",
      "[Test ] Step: 67000, acc: 0.76562\n",
      "[Train] Step: 67500, loss: 0.00000, acc: 1.00000\n",
      "(4800, 64, 64, 3)\n",
      "(4800,)\n",
      "[Test ] Step: 67500, acc: 0.62500\n",
      "[Train] Step: 68000, loss: 0.00000, acc: 1.00000\n",
      "(4800, 64, 64, 3)\n",
      "(4800,)\n",
      "[Test ] Step: 68000, acc: 0.64062\n",
      "[Train] Step: 68500, loss: 0.00000, acc: 1.00000\n",
      "(4800, 64, 64, 3)\n",
      "(4800,)\n",
      "[Test ] Step: 68500, acc: 0.64062\n",
      "[Train] Step: 69000, loss: 0.00000, acc: 1.00000\n",
      "(4800, 64, 64, 3)\n",
      "(4800,)\n",
      "[Test ] Step: 69000, acc: 0.64062\n",
      "[Train] Step: 69500, loss: 0.00000, acc: 1.00000\n",
      "(4800, 64, 64, 3)\n",
      "(4800,)\n",
      "[Test ] Step: 69500, acc: 0.60938\n",
      "[Train] Step: 70000, loss: 0.00000, acc: 1.00000\n",
      "(4800, 64, 64, 3)\n",
      "(4800,)\n",
      "[Test ] Step: 70000, acc: 0.65625\n",
      "[Train] Step: 70500, loss: 0.00000, acc: 1.00000\n",
      "(4800, 64, 64, 3)\n",
      "(4800,)\n",
      "[Test ] Step: 70500, acc: 0.59375\n",
      "[Train] Step: 71000, loss: 0.00000, acc: 1.00000\n",
      "(4800, 64, 64, 3)\n",
      "(4800,)\n",
      "[Test ] Step: 71000, acc: 0.59375\n",
      "[Train] Step: 71500, loss: 0.00000, acc: 1.00000\n",
      "(4800, 64, 64, 3)\n",
      "(4800,)\n",
      "[Test ] Step: 71500, acc: 0.65625\n",
      "[Train] Step: 72000, loss: 0.00000, acc: 1.00000\n",
      "(4800, 64, 64, 3)\n",
      "(4800,)\n",
      "[Test ] Step: 72000, acc: 0.57812\n",
      "[Train] Step: 72500, loss: 0.00000, acc: 1.00000\n",
      "(4800, 64, 64, 3)\n",
      "(4800,)\n",
      "[Test ] Step: 72500, acc: 0.57812\n",
      "[Train] Step: 73000, loss: 0.00000, acc: 1.00000\n",
      "(4800, 64, 64, 3)\n",
      "(4800,)\n",
      "[Test ] Step: 73000, acc: 0.57812\n",
      "[Train] Step: 73500, loss: 0.00000, acc: 1.00000\n",
      "(4800, 64, 64, 3)\n",
      "(4800,)\n",
      "[Test ] Step: 73500, acc: 0.53125\n",
      "[Train] Step: 74000, loss: 0.00000, acc: 1.00000\n",
      "(4800, 64, 64, 3)\n",
      "(4800,)\n",
      "[Test ] Step: 74000, acc: 0.51562\n",
      "[Train] Step: 74500, loss: 0.00000, acc: 1.00000\n",
      "(4800, 64, 64, 3)\n",
      "(4800,)\n",
      "[Test ] Step: 74500, acc: 0.54688\n",
      "[Train] Step: 75000, loss: 0.00000, acc: 1.00000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4800, 64, 64, 3)\n",
      "(4800,)\n",
      "[Test ] Step: 75000, acc: 0.54688\n",
      "[Train] Step: 75500, loss: 0.00000, acc: 1.00000\n",
      "(4800, 64, 64, 3)\n",
      "(4800,)\n",
      "[Test ] Step: 75500, acc: 0.62500\n",
      "[Train] Step: 76000, loss: 0.00010, acc: 1.00000\n",
      "(4800, 64, 64, 3)\n",
      "(4800,)\n",
      "[Test ] Step: 76000, acc: 0.62500\n",
      "[Train] Step: 76500, loss: 0.00000, acc: 1.00000\n",
      "(4800, 64, 64, 3)\n",
      "(4800,)\n",
      "[Test ] Step: 76500, acc: 0.62500\n",
      "[Train] Step: 77000, loss: 0.00000, acc: 1.00000\n",
      "(4800, 64, 64, 3)\n",
      "(4800,)\n",
      "[Test ] Step: 77000, acc: 0.64062\n",
      "[Train] Step: 77500, loss: 0.00000, acc: 1.00000\n",
      "(4800, 64, 64, 3)\n",
      "(4800,)\n",
      "[Test ] Step: 77500, acc: 0.64062\n",
      "[Train] Step: 78000, loss: 0.00000, acc: 1.00000\n",
      "(4800, 64, 64, 3)\n",
      "(4800,)\n",
      "[Test ] Step: 78000, acc: 0.64062\n",
      "[Train] Step: 78500, loss: 0.00000, acc: 1.00000\n",
      "(4800, 64, 64, 3)\n",
      "(4800,)\n",
      "[Test ] Step: 78500, acc: 0.67188\n",
      "[Train] Step: 79000, loss: 0.00000, acc: 1.00000\n",
      "(4800, 64, 64, 3)\n",
      "(4800,)\n",
      "[Test ] Step: 79000, acc: 0.62500\n",
      "[Train] Step: 79500, loss: 0.00000, acc: 1.00000\n",
      "(4800, 64, 64, 3)\n",
      "(4800,)\n",
      "[Test ] Step: 79500, acc: 0.64062\n",
      "[Train] Step: 80000, loss: 0.00000, acc: 1.00000\n",
      "(4800, 64, 64, 3)\n",
      "(4800,)\n",
      "[Test ] Step: 80000, acc: 0.65625\n",
      "[Train] Step: 80500, loss: 0.00000, acc: 1.00000\n",
      "(4800, 64, 64, 3)\n",
      "(4800,)\n",
      "[Test ] Step: 80500, acc: 0.62500\n",
      "[Train] Step: 81000, loss: 0.00000, acc: 1.00000\n",
      "(4800, 64, 64, 3)\n",
      "(4800,)\n",
      "[Test ] Step: 81000, acc: 0.64062\n",
      "[Train] Step: 81500, loss: 0.00000, acc: 1.00000\n",
      "(4800, 64, 64, 3)\n",
      "(4800,)\n",
      "[Test ] Step: 81500, acc: 0.64062\n",
      "[Train] Step: 82000, loss: 0.00000, acc: 1.00000\n",
      "(4800, 64, 64, 3)\n",
      "(4800,)\n",
      "[Test ] Step: 82000, acc: 0.65625\n",
      "[Train] Step: 82500, loss: 0.00000, acc: 1.00000\n",
      "(4800, 64, 64, 3)\n",
      "(4800,)\n",
      "[Test ] Step: 82500, acc: 0.67188\n",
      "[Train] Step: 83000, loss: 0.00000, acc: 1.00000\n",
      "(4800, 64, 64, 3)\n",
      "(4800,)\n",
      "[Test ] Step: 83000, acc: 0.67188\n",
      "[Train] Step: 83500, loss: 0.00000, acc: 1.00000\n",
      "(4800, 64, 64, 3)\n",
      "(4800,)\n",
      "[Test ] Step: 83500, acc: 0.67188\n",
      "[Train] Step: 84000, loss: 0.00000, acc: 1.00000\n",
      "(4800, 64, 64, 3)\n",
      "(4800,)\n",
      "[Test ] Step: 84000, acc: 0.67188\n",
      "[Train] Step: 84500, loss: 0.00000, acc: 1.00000\n",
      "(4800, 64, 64, 3)\n",
      "(4800,)\n",
      "[Test ] Step: 84500, acc: 0.70312\n",
      "[Train] Step: 85000, loss: 0.00000, acc: 1.00000\n",
      "(4800, 64, 64, 3)\n",
      "(4800,)\n",
      "[Test ] Step: 85000, acc: 0.62500\n",
      "[Train] Step: 85500, loss: 0.00000, acc: 1.00000\n",
      "(4800, 64, 64, 3)\n",
      "(4800,)\n",
      "[Test ] Step: 85500, acc: 0.64062\n",
      "[Train] Step: 86000, loss: 0.00000, acc: 1.00000\n",
      "(4800, 64, 64, 3)\n",
      "(4800,)\n",
      "[Test ] Step: 86000, acc: 0.62500\n",
      "[Train] Step: 86500, loss: 0.00000, acc: 1.00000\n",
      "(4800, 64, 64, 3)\n",
      "(4800,)\n",
      "[Test ] Step: 86500, acc: 0.62500\n",
      "[Train] Step: 87000, loss: 0.00000, acc: 1.00000\n",
      "(4800, 64, 64, 3)\n",
      "(4800,)\n",
      "[Test ] Step: 87000, acc: 0.62500\n",
      "[Train] Step: 87500, loss: 0.00000, acc: 1.00000\n",
      "(4800, 64, 64, 3)\n",
      "(4800,)\n",
      "[Test ] Step: 87500, acc: 0.64062\n",
      "[Train] Step: 88000, loss: 0.00000, acc: 1.00000\n",
      "(4800, 64, 64, 3)\n",
      "(4800,)\n",
      "[Test ] Step: 88000, acc: 0.67188\n",
      "[Train] Step: 88500, loss: 0.00000, acc: 1.00000\n",
      "(4800, 64, 64, 3)\n",
      "(4800,)\n",
      "[Test ] Step: 88500, acc: 0.75000\n",
      "[Train] Step: 89000, loss: 0.00000, acc: 1.00000\n",
      "(4800, 64, 64, 3)\n",
      "(4800,)\n",
      "[Test ] Step: 89000, acc: 0.76562\n",
      "[Train] Step: 89500, loss: 0.00000, acc: 1.00000\n",
      "(4800, 64, 64, 3)\n",
      "(4800,)\n",
      "[Test ] Step: 89500, acc: 0.67188\n",
      "[Train] Step: 90000, loss: 0.00000, acc: 1.00000\n",
      "(4800, 64, 64, 3)\n",
      "(4800,)\n",
      "[Test ] Step: 90000, acc: 0.71875\n",
      "[Train] Step: 90500, loss: 0.00000, acc: 1.00000\n",
      "(4800, 64, 64, 3)\n",
      "(4800,)\n",
      "[Test ] Step: 90500, acc: 0.70312\n",
      "[Train] Step: 91000, loss: 0.00000, acc: 1.00000\n",
      "(4800, 64, 64, 3)\n",
      "(4800,)\n",
      "[Test ] Step: 91000, acc: 0.76562\n",
      "[Train] Step: 91500, loss: 0.00000, acc: 1.00000\n",
      "(4800, 64, 64, 3)\n",
      "(4800,)\n",
      "[Test ] Step: 91500, acc: 0.65625\n",
      "[Train] Step: 92000, loss: 0.00000, acc: 1.00000\n",
      "(4800, 64, 64, 3)\n",
      "(4800,)\n",
      "[Test ] Step: 92000, acc: 0.67188\n",
      "[Train] Step: 92500, loss: 0.00000, acc: 1.00000\n",
      "(4800, 64, 64, 3)\n",
      "(4800,)\n",
      "[Test ] Step: 92500, acc: 0.65625\n",
      "[Train] Step: 93000, loss: 0.00000, acc: 1.00000\n",
      "(4800, 64, 64, 3)\n",
      "(4800,)\n",
      "[Test ] Step: 93000, acc: 0.60938\n",
      "[Train] Step: 93500, loss: 0.00000, acc: 1.00000\n",
      "(4800, 64, 64, 3)\n",
      "(4800,)\n",
      "[Test ] Step: 93500, acc: 0.65625\n",
      "[Train] Step: 94000, loss: 0.00000, acc: 1.00000\n",
      "(4800, 64, 64, 3)\n",
      "(4800,)\n",
      "[Test ] Step: 94000, acc: 0.65625\n",
      "[Train] Step: 94500, loss: 0.00000, acc: 1.00000\n",
      "(4800, 64, 64, 3)\n",
      "(4800,)\n",
      "[Test ] Step: 94500, acc: 0.65625\n",
      "[Train] Step: 95000, loss: 0.00000, acc: 1.00000\n",
      "(4800, 64, 64, 3)\n",
      "(4800,)\n",
      "[Test ] Step: 95000, acc: 0.67188\n",
      "[Train] Step: 95500, loss: 0.00000, acc: 1.00000\n",
      "(4800, 64, 64, 3)\n",
      "(4800,)\n",
      "[Test ] Step: 95500, acc: 0.65625\n",
      "[Train] Step: 96000, loss: 0.00000, acc: 1.00000\n",
      "(4800, 64, 64, 3)\n",
      "(4800,)\n",
      "[Test ] Step: 96000, acc: 0.65625\n",
      "[Train] Step: 96500, loss: 0.00000, acc: 1.00000\n",
      "(4800, 64, 64, 3)\n",
      "(4800,)\n",
      "[Test ] Step: 96500, acc: 0.64062\n",
      "[Train] Step: 97000, loss: 0.00000, acc: 1.00000\n",
      "(4800, 64, 64, 3)\n",
      "(4800,)\n",
      "[Test ] Step: 97000, acc: 0.64062\n",
      "[Train] Step: 97500, loss: 0.00000, acc: 1.00000\n",
      "(4800, 64, 64, 3)\n",
      "(4800,)\n",
      "[Test ] Step: 97500, acc: 0.64062\n",
      "[Train] Step: 98000, loss: 0.00000, acc: 1.00000\n",
      "(4800, 64, 64, 3)\n",
      "(4800,)\n",
      "[Test ] Step: 98000, acc: 0.67188\n",
      "[Train] Step: 98500, loss: 0.00000, acc: 1.00000\n",
      "(4800, 64, 64, 3)\n",
      "(4800,)\n",
      "[Test ] Step: 98500, acc: 0.67188\n",
      "[Train] Step: 99000, loss: 0.00000, acc: 1.00000\n",
      "(4800, 64, 64, 3)\n",
      "(4800,)\n",
      "[Test ] Step: 99000, acc: 0.67188\n",
      "[Train] Step: 99500, loss: 0.00000, acc: 1.00000\n",
      "(4800, 64, 64, 3)\n",
      "(4800,)\n",
      "[Test ] Step: 99500, acc: 0.67188\n",
      "[Train] Step: 100000, loss: 0.00000, acc: 1.00000\n",
      "(4800, 64, 64, 3)\n",
      "(4800,)\n",
      "[Test ] Step: 100000, acc: 0.67188\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "x = tf.placeholder(tf.float32, [None, 64, 64, 3])\n",
    "#x = tf.placeholder(tf.float32, [None, 3072])\n",
    "y = tf.placeholder(tf.int64, [None])\n",
    "# [None], eg: [0,5,6,3]\n",
    "#x_image = tf.reshape(x, [-1, 3, 32, 32])\n",
    "# 32*32\n",
    "#x_image = tf.transpose(x_image, perm=[0, 2, 3, 1])\n",
    "\n",
    "# conv1: 神经元图， feature_map, 输出图像\n",
    "conv1 = tf.layers.conv2d(x,\n",
    "                         64, # output channel number\n",
    "                         (5,5), # kernel size\n",
    "                         strides=(2, 2),\n",
    "                         padding = 'same',\n",
    "                         activation = tf.nn.relu,\n",
    "                         )\n",
    "bn1 = tf.contrib.layers.batch_norm(conv1, center=True, scale=True,\n",
    "                                          decay=0.9,\n",
    "                                          updates_collections=None)\n",
    "d1 = tf.layers.dropout(\n",
    "    bn1,\n",
    "    rate=0.5,\n",
    "    noise_shape=None,\n",
    "    seed=None,\n",
    "    training=False,\n",
    "    name=None\n",
    "    )\n",
    "\n",
    "\n",
    "conv2 = tf.layers.conv2d(d1,\n",
    "                         128, # output channel number\n",
    "                         (5,5), # kernel size\n",
    "                         strides=(2, 2),\n",
    "                         padding = 'same',\n",
    "                         activation = tf.nn.relu,\n",
    "                         )\n",
    "bn2 = tf.contrib.layers.batch_norm(conv2, center=True, scale=True,\n",
    "                                          decay=0.9, \n",
    "                                          updates_collections=None)\n",
    "d2 = tf.layers.dropout(\n",
    "    bn2,\n",
    "    rate=0.5,\n",
    "    noise_shape=None,\n",
    "    seed=None,\n",
    "    training=False,\n",
    "    name=None\n",
    "    )\n",
    "\n",
    "conv3 = tf.layers.conv2d(d2,\n",
    "                         256, # output channel number\n",
    "                         (5,5), # kernel size\n",
    "                         strides=(2, 2),\n",
    "                         padding = 'same',\n",
    "                         activation = tf.nn.relu,\n",
    "                         )\n",
    "bn3 = tf.contrib.layers.batch_norm(conv3, center=True, scale=True,\n",
    "                                          decay=0.9, \n",
    "                                          updates_collections=None)\n",
    "d3 = tf.layers.dropout(\n",
    "    bn3,\n",
    "    rate=0.5,\n",
    "    noise_shape=None,\n",
    "    seed=None,\n",
    "    training=False,\n",
    "    name=None\n",
    "    )\n",
    "\n",
    "# [None, 4 * 4 * 32]\n",
    "flatten = tf.layers.flatten(d3)\n",
    "y_ = tf.layers.dense(flatten, 6)\n",
    "\n",
    "loss = tf.losses.sparse_softmax_cross_entropy(labels=y, logits=y_)\n",
    "# y_ -> sofmax\n",
    "# y -> one_hot\n",
    "# loss = ylogy_\n",
    "\n",
    "# indices\n",
    "predict = tf.argmax(y_, 1)\n",
    "# [1,0,1,1,1,0,0,0]\n",
    "correct_prediction = tf.equal(predict, y)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float64))\n",
    "\n",
    "with tf.name_scope('train_op'):\n",
    "    train_op = tf.train.AdamOptimizer(1e-3).minimize(loss)\n",
    "init = tf.global_variables_initializer()\n",
    "batch_size = 64\n",
    "train_steps = 100000\n",
    "test_steps = 5\n",
    "\n",
    "# train 10k: 71.35%\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    all_steps = []\n",
    "    all_train_acc = []\n",
    "    all_test_steps = []\n",
    "    all_test_acc = []\n",
    "    all_test_acc_val = []\n",
    "    all_loss = []\n",
    "    saver = tf.train.Saver()\n",
    "    #show_all_variables()\n",
    "    # log dir\n",
    "    #summary_op = tf.summary.merge_all()\n",
    "\n",
    "    #writer = tf.summary.FileWriter(\"./logs/\" + '_'.join(\n",
    "        #[config.DATASET_TRAIN, config.MODEL_NAME]), sess.graph)\n",
    "\n",
    "    log_prefix = './checkpoint' + '/' + 'train_cDCGAN'\n",
    "    counter = 1\n",
    "    #start_time = time.time()\n",
    "    could_load, checkpoint_counter = load(log_prefix, saver, sess)\n",
    "    if could_load:\n",
    "        counter = checkpoint_counter\n",
    "        print(\" [*] Load SUCCESS\")\n",
    "    else:\n",
    "        print(\" [!] Load failed...\")\n",
    "    for i in range(train_steps):\n",
    "        \n",
    "        \n",
    "        \n",
    "        batch_data, batch_labels = train_data.next_batch(batch_size)\n",
    "        loss_val, acc_val, _ = sess.run(\n",
    "            [loss, accuracy, train_op],\n",
    "            feed_dict={\n",
    "                x: batch_data,\n",
    "                y: batch_labels})\n",
    "        if (i+1) % 500 == 0:\n",
    "            save(log_prefix, counter, saver, sess)\n",
    "            print('[Train] Step: %d, loss: %4.5f, acc: %4.5f' \n",
    "                  % (i+1, loss_val, acc_val))\n",
    "            all_steps.append(i)\n",
    "            all_train_acc.append(acc_val)\n",
    "            all_loss.append(loss_val)\n",
    "            #if (i+1) % 1000 == 0:\n",
    "            test_data = SteelData(False,False)\n",
    "\n",
    "\n",
    "            test_batch_data, test_batch_labels \\\n",
    "                        = test_data.next_batch(batch_size)\n",
    "            test_acc_val = sess.run(\n",
    "                        [accuracy],\n",
    "                        feed_dict = {\n",
    "                            x: test_batch_data, \n",
    "                            y: test_batch_labels\n",
    "                        })\n",
    "            all_test_acc_val.append(test_acc_val)\n",
    "\n",
    "            all_test_steps.append(i)\n",
    "            #test_acc = np.mean(all_test_acc_val)\n",
    "            test_acc =  np.mean(test_acc_val)\n",
    "        #all_test_acc.append(test_acc)\n",
    "            print('[Test ] Step: %d, acc: %4.5f'\n",
    "                  % (i+1, test_acc))\n",
    "            counter += 1\n",
    "    #print(all_steps)      \n",
    "    #print(all_train_acc)\n",
    "    fig,ax = plt.subplots()\n",
    " \n",
    "    #plt.xlabel('migration speed (MB/s)')\n",
    "    #plt.ylabel('migration time (s); request delay (ms)')\n",
    "\n",
    "    \"\"\"set interval for y label\"\"\"\n",
    "    #yticks = range(0,1,11)\n",
    "    #ax.set_yticks(yticks)\n",
    "\n",
    "\n",
    "    \"\"\"set min and max value for axes\"\"\"\n",
    "    #ax.set_ylim([0,1])\n",
    "    ax.set_xlim([0,100000])\n",
    "\n",
    "\n",
    "    #x = [57,56,55,54,53,52,51,50,49,48,47,46,45,44,43]\n",
    "    line1, = plt.plot(all_steps,all_train_acc,label=\"train accrucy\")\n",
    "    line2, =plt.plot(all_steps,all_test_acc_val,'-.',label=\"test accrucy\")\n",
    "    line3, =plt.plot(all_steps,all_loss,'--',label=\"test accrucy\")\n",
    "    #plt.plot(all_steps,all_test_acc_val,\"+-\",label=\"request delay\")\n",
    "\n",
    "    \"\"\"open the grid\"\"\"\n",
    "    plt.grid(True)\n",
    "\n",
    "    #plt.legend(bbox_to_anchor=(1.0, 1), loc=1, borderaxespad=0.)\n",
    "    plt.legend([line1, line2,line3], ['train accrucy', 'test accrucy','loss'], loc = 'best') \n",
    "    #plt.savefig('./test.png')\n",
    "    plt.savefig('./test1.png')\n",
    "    plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(all_test_acc_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots()\n",
    " \n",
    "#plt.xlabel('migration speed (MB/s)')\n",
    "    #plt.ylabel('migration time (s); request delay (ms)')\n",
    "\n",
    "    #\"\"\"set interval for y label\"\"\"\n",
    "    #yticks = range(0,1,11)\n",
    "    #ax.set_yticks(yticks)\n",
    "\n",
    "\n",
    "    #\"\"\"set min and max value for axes\"\"\"\n",
    "ax.set_ylim([0,1.1])\n",
    "ax.set_xlim([0,10000])\n",
    "\n",
    "\n",
    "    #x = [57,56,55,54,53,52,51,50,49,48,47,46,45,44,43]\n",
    "line1, = plt.plot(all_steps,all_train_acc,label=\"train accrucy\")\n",
    "line2, =plt.plot(all_steps,all_test_acc_val,'-.',label=\"test accrucy\")\n",
    "    #plt.plot(all_steps,all_test_acc_val,\"+-\",label=\"request delay\")\n",
    "\n",
    " #\"\"\"open the grid\"\"\"\n",
    "plt.grid(True)\n",
    "\n",
    "    #plt.legend(bbox_to_anchor=(1.0, 1), loc=1, borderaxespad=0.)\n",
    "plt.legend([line1, line2], ['train accrucy', 'test accrucy'], loc = 'best') \n",
    "plt.savefig('./test.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots()\n",
    " \n",
    "#plt.xlabel('migration speed (MB/s)')\n",
    "    #plt.ylabel('migration time (s); request delay (ms)')\n",
    "\n",
    "    #\"\"\"set interval for y label\"\"\"\n",
    "    #yticks = range(0,1,11)\n",
    "    #ax.set_yticks(yticks)\n",
    "\n",
    "\n",
    "    #\"\"\"set min and max value for axes\"\"\"\n",
    "#ax.set_ylim([0,1.1])\n",
    "ax.set_xlim([0,10000])\n",
    "\n",
    "\n",
    "    #x = [57,56,55,54,53,52,51,50,49,48,47,46,45,44,43]\n",
    "#line1, = plt.plot(all_steps,all_train_acc,label=\"train accrucy\")\n",
    "#line2, =plt.plot(all_steps,all_test_acc_val,'-.',label=\"test accrucy\")\n",
    "    #plt.plot(all_steps,all_test_acc_val,\"+-\",label=\"request delay\")\n",
    "\n",
    " #\"\"\"open the grid\"\"\"\n",
    "plt.grid(True)\n",
    "plt.plot(all_steps,all_loss,'--',label=\"test accrucy\")\n",
    "    #plt.legend(bbox_to_anchor=(1.0, 1), loc=1, borderaxespad=0.)\n",
    "#plt.legend([line1, line2], ['train accrucy', 'test accrucy'], loc = 'best') \n",
    "plt.savefig('./test2.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row1 = all_train_acc\n",
    "print(row1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row2 = all_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = list(map(lambda x:[x],row1))\n",
    "with open('3.csv','w') as f:\n",
    "    f_csv = csv.writer(f)\n",
    "    for i in data:\n",
    "            f_csv.writerow(i)\n",
    "    #f_csv.writerows(row2)\n",
    "    #f_csv.writerows(row1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(all_test_acc_val[-6:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
